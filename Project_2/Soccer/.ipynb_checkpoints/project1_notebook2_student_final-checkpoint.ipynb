{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [L&S 88]  Open Science -- Project 1, part 2\n",
    "---\n",
    "\n",
    "### Instructor: Josh Quan & Eric Van Dusen\n",
    "\n",
    "The key takeaway of this notebook is that the outcome of your notebook depends on the decision points that you take as you build your model. Picking different variables, keeping or removing outliers, aggregating one way versus another, are all examples of such important decisions. On this notebook, you will first observe how the different elements that we picked to build our sample model contributed to our final solution. After you review the model that we have pre-made for you, it would be your turn to build your own path!\n",
    "\n",
    "**Topics Covered:**\n",
    "* Building a model - where EDA matters\n",
    "* Building your own path - how distinct decision points affect the final outcome\n",
    "\n",
    "**Table of Contents:**\n",
    "\n",
    "[Data](#section1)<br>\n",
    "\n",
    "[Sample Model](#section2) <br>\n",
    "1. [General](#section3)<br>\n",
    "\n",
    "2. [Decision Point 1](#section4) <br>\n",
    "\n",
    "3. [Decision Point 2](#section5) <br>\n",
    "\n",
    "4. [Decision Point 3](#section6) <br>\n",
    "\n",
    "5. [Decision Point 4](#section7) <br>\n",
    "\n",
    "6. [Decision Point 5](#section8) <br>\n",
    "\n",
    "\n",
    "[ Deciding your own adventure!](#section9) <br>\n",
    "1. [Decision Point 1](#section10) <br>\n",
    "\n",
    "2. [Decision Point 2](#section11) <br>\n",
    "\n",
    "3. [Decision Point 3](#section12) <br>\n",
    "\n",
    "4. [Decision Point 4](#section13) <br>\n",
    "\n",
    "5. [Decision Point 5](#section14) <br>\n",
    "\n",
    "6. [Decision Point 6](#section15) <br>\n",
    "\n",
    "7. [Decision Point 7](#section16) <br>\n",
    "\n",
    "\n",
    "Please run the cell below before you begin.\n",
    "#### Dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data<a id='section1'></a>\n",
    "---\n",
    "\n",
    "We will be working on the same data set as in the previous notebook. We have included the data dictionary below for your  reference. \n",
    "\n",
    "|Variable Name   | Description |\n",
    "|--------------|------------|\n",
    "|`player` | player's name |\n",
    "|`club` | player's soccer club (team) |\n",
    "|`leagueCountry`| country of player club (England, Germany, France, and Spain) |\n",
    "|`height` | player height (in cm) |\n",
    "|`games`| number of games in the player-referee dyad |\n",
    "|`position` | detailed player position |\n",
    "|`goals`| goals scored by a player in the player-referee dyad |\n",
    "|`yellowCards`| number of yellow cards player received from referee |\n",
    "|`yellowReds`| number of yellow-red cards player received from referee |\n",
    "|`redCards`| number of red cards player received from referee |\n",
    "|`rater1`| skin rating of photo by rater 1 (5-point scale ranging from very light skin to very dark skin |\n",
    "|`rater2`| skin rating of photo by rater 2 (5-point scale ranging from very light skin to very dark skin |\n",
    "|`meanIAT`|  mean implicit bias score (using the race IAT) for referee country, higher values correspond to faster white good, black bad associations |\n",
    "|`meanExp`| mean explicit bias score (using a racial thermometer task) for referee country, higher values correspond to greater feelings of warmth toward whites versus blacks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>playerShort</th> <th>player</th> <th>club</th> <th>leagueCountry</th> <th>birthday</th> <th>height</th> <th>weight</th> <th>position</th> <th>games</th> <th>victories</th> <th>ties</th> <th>defeats</th> <th>goals</th> <th>yellowCards</th> <th>yellowReds</th> <th>redCards</th> <th>photoID</th> <th>rater1</th> <th>rater2</th> <th>refNum</th> <th>refCountry</th> <th>Alpha_3</th> <th>meanIAT</th> <th>nIAT</th> <th>seIAT</th> <th>meanExp</th> <th>nExp</th> <th>seExp</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>lucas-wilchez</td> <td>Lucas Wilchez</td> <td>Real Zaragoza  </td> <td>Spain        </td> <td>31.08.1983</td> <td>177   </td> <td>72    </td> <td>Attacking Midfielder</td> <td>1    </td> <td>0        </td> <td>0   </td> <td>1      </td> <td>0    </td> <td>0          </td> <td>0         </td> <td>0       </td> <td>95212.jpg</td> <td>0.25  </td> <td>0.5   </td> <td>1     </td> <td>1         </td> <td>GRC    </td> <td>0.326391</td> <td>712 </td> <td>0.000564112</td> <td>0.396    </td> <td>750 </td> <td>0.00269649</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>john-utaka   </td> <td>John Utaka   </td> <td>Montpellier HSC</td> <td>France       </td> <td>08.01.1982</td> <td>179   </td> <td>82    </td> <td>Right Winger        </td> <td>1    </td> <td>0        </td> <td>0   </td> <td>1      </td> <td>0    </td> <td>1          </td> <td>0         </td> <td>0       </td> <td>1663.jpg </td> <td>0.75  </td> <td>0.75  </td> <td>2     </td> <td>2         </td> <td>ZMB    </td> <td>0.203375</td> <td>40  </td> <td>0.0108749  </td> <td>-0.204082</td> <td>49  </td> <td>0.0615044 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>abdon-prats  </td> <td> Abdón Prats </td> <td>RCD Mallorca   </td> <td>Spain        </td> <td>17.12.1992</td> <td>181   </td> <td>79    </td> <td>nan                 </td> <td>1    </td> <td>0        </td> <td>1   </td> <td>0      </td> <td>0    </td> <td>1          </td> <td>0         </td> <td>0       </td> <td>nan      </td> <td>nan   </td> <td>nan   </td> <td>3     </td> <td>3         </td> <td>ESP    </td> <td>0.369894</td> <td>1785</td> <td>0.00022949 </td> <td>0.588297 </td> <td>1897</td> <td>0.00100165</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>pablo-mari   </td> <td> Pablo Marí  </td> <td>RCD Mallorca   </td> <td>Spain        </td> <td>31.08.1993</td> <td>191   </td> <td>87    </td> <td>Center Back         </td> <td>1    </td> <td>1        </td> <td>0   </td> <td>0      </td> <td>0    </td> <td>0          </td> <td>0         </td> <td>0       </td> <td>nan      </td> <td>nan   </td> <td>nan   </td> <td>3     </td> <td>3         </td> <td>ESP    </td> <td>0.369894</td> <td>1785</td> <td>0.00022949 </td> <td>0.588297 </td> <td>1897</td> <td>0.00100165</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ruben-pena   </td> <td> Rubén Peña  </td> <td>Real Valladolid</td> <td>Spain        </td> <td>18.07.1991</td> <td>172   </td> <td>70    </td> <td>Right Midfielder    </td> <td>1    </td> <td>1        </td> <td>0   </td> <td>0      </td> <td>0    </td> <td>0          </td> <td>0         </td> <td>0       </td> <td>nan      </td> <td>nan   </td> <td>nan   </td> <td>3     </td> <td>3         </td> <td>ESP    </td> <td>0.369894</td> <td>1785</td> <td>0.00022949 </td> <td>0.588297 </td> <td>1897</td> <td>0.00100165</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (146023 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soccer = Table.read_table('CrowdstormingDataJuly1st.csv')\n",
    "soccer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sample Model<a id='section2'></a>\n",
    "---\n",
    "\n",
    "On this section, we will explore different decisions points, including data cleaning, transformations, and aggregations. We will use several of the EDA techniques that we learned on the previous part since EDA provides us with a frame for interesting details to focus that otherwise are easy to overlook. For instance, it can help us identify if variables have missing values, if a column had extreme outliers, if two numerical variables are perfectly correlated, etc. These points are important because they can drastically affect the performance of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### General :<a id='section3'></a>\n",
    "--- \n",
    "Often times, we want to look at the summary statistics of different variables (e.g. min, max, mean, median, etc.) before you start running any models. The goal of this is to get to know your data and to avoid running into issues down the road. We will begin by looking at some summary statistics, then we will create some metrics to see if there is anything useful we can use in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by selecting only the variables we are interested in using the function select(). Namely, `birthday`,`height`,`weight`,`games`,`victories`,`ties`,`defeats`,`goal`,`yellowCards`,`yellowReds`,`redCards`,`rater1`,`rater2`, `meabIAT`,`meanExp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>height</th> <th>weight</th> <th>games</th> <th>victories</th> <th>ties</th> <th>defeats</th> <th>goals</th> <th>yellowCards</th> <th>yellowReds</th> <th>redCards</th> <th>rater1</th> <th>rater2</th> <th>meanIAT</th> <th>meanExp</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>177   </td> <td>72    </td> <td>1    </td> <td>0        </td> <td>0   </td> <td>1      </td> <td>0    </td> <td>0          </td> <td>0         </td> <td>0       </td> <td>0.25  </td> <td>0.5   </td> <td>0.326391</td> <td>0.396    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>179   </td> <td>82    </td> <td>1    </td> <td>0        </td> <td>0   </td> <td>1      </td> <td>0    </td> <td>1          </td> <td>0         </td> <td>0       </td> <td>0.75  </td> <td>0.75  </td> <td>0.203375</td> <td>-0.204082</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>181   </td> <td>79    </td> <td>1    </td> <td>0        </td> <td>1   </td> <td>0      </td> <td>0    </td> <td>1          </td> <td>0         </td> <td>0       </td> <td>nan   </td> <td>nan   </td> <td>0.369894</td> <td>0.588297 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>191   </td> <td>87    </td> <td>1    </td> <td>1        </td> <td>0   </td> <td>0      </td> <td>0    </td> <td>0          </td> <td>0         </td> <td>0       </td> <td>nan   </td> <td>nan   </td> <td>0.369894</td> <td>0.588297 </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>172   </td> <td>70    </td> <td>1    </td> <td>1        </td> <td>0   </td> <td>0      </td> <td>0    </td> <td>0          </td> <td>0         </td> <td>0       </td> <td>nan   </td> <td>nan   </td> <td>0.369894</td> <td>0.588297 </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (146023 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantitative=soccer.select(\"height\",\"weight\",\"games\",\"victories\",\"ties\",\"defeats\",\"goals\",\"yellowCards\",\"yellowReds\",\"redCards\",\"rater1\",\"rater2\", \"meanIAT\",\"meanExp\")\n",
    "quantitative.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will calculate some summary statistics for the whole table. Let's begin by finding the min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min height: 161.0\n",
      "Min weight: 54.0\n",
      "Min games: 1\n",
      "Min victories: 0\n",
      "Min ties: 0\n",
      "Min defeats: 0\n",
      "Min goals: 0\n",
      "Min yellowCards: 0\n",
      "Min yellowReds: 0\n",
      "Min redCards: 0\n",
      "Min rater1: 0.0\n",
      "Min rater2: 0.0\n",
      "Min meanIAT: -0.0472542252767709\n",
      "Min meanExp: -1.375\n"
     ]
    }
   ],
   "source": [
    "for col_index in range(len(quantitative)):\n",
    "    print(\"Min {}: {}\".format(quantitative.labels[col_index],min(quantitative.column(col_index))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's inspect the **max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max height: 203.0\n",
      "Max weight: 100.0\n",
      "Max games: 47\n",
      "Max victories: 29\n",
      "Max ties: 14\n",
      "Max defeats: 18\n",
      "Max goals: 23\n",
      "Max yellowCards: 14\n",
      "Max yellowReds: 3\n",
      "Max redCards: 2\n",
      "Max rater1: 1.0\n",
      "Max rater2: 1.0\n",
      "Max meanIAT: 0.573793286802122\n",
      "Max meanExp: 1.8\n"
     ]
    }
   ],
   "source": [
    "for col_index in range(len(quantitative)):\n",
    "    print(\"Max {}: {}\".format(quantitative.labels[col_index],max(quantitative.column(col_index))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will see the number of **missing values** in each of our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan height: 263\n",
      "Number of nan weight: 2243\n",
      "Number of nan games: 0\n",
      "Number of nan victories: 0\n",
      "Number of nan ties: 0\n",
      "Number of nan defeats: 0\n",
      "Number of nan goals: 0\n",
      "Number of nan yellowCards: 0\n",
      "Number of nan yellowReds: 0\n",
      "Number of nan redCards: 0\n",
      "Number of nan rater1: 21407\n",
      "Number of nan rater2: 21407\n",
      "Number of nan meanIAT: 163\n",
      "Number of nan meanExp: 163\n"
     ]
    }
   ],
   "source": [
    "for col_index in range(len(quantitative)):\n",
    "    print(\"Number of nan {}: {}\".format(quantitative.labels[col_index],sum(np.isnan(quantitative.column(col_index)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interesting point to consider in the future sections. As you can notice, there are over 20,000 missing data values for certain variables. You should think about what this means for your analysis and if you should include them and how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data also means that we cannot use traditional functions to calculate the sum, mean, and median. This is because the functions do not know to perform algebraic operations non-existing and non-numerical values, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array([1,3,4,np.nan]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the two cells below. One uses **np.sum** and the other **np.nansum**. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum with nan height: nan\n",
      "Sum with nan weight: nan\n",
      "Sum with nan games: 426572\n",
      "Sum with nan victories: 186674\n",
      "Sum with nan ties: 103423\n",
      "Sum with nan defeats: 136475\n",
      "Sum with nan goals: 49366\n",
      "Sum with nan yellowCards: 56274\n",
      "Sum with nan yellowReds: 1662\n",
      "Sum with nan redCards: 1834\n",
      "Sum with nan rater1: nan\n",
      "Sum with nan rater2: nan\n",
      "Sum with nan meanIAT: nan\n",
      "Sum with nan meanExp: nan\n"
     ]
    }
   ],
   "source": [
    "#np.sum\n",
    "for col_index in range(len(quantitative)):\n",
    "    print(\"Sum with nan {}: {}\".format(quantitative.labels[col_index],np.sum(quantitative.column(col_index))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum without nan height: 26519892.0\n",
      "Sum without nan weight: 10938539.0\n",
      "Sum without nan games: 426572\n",
      "Sum without nan victories: 186674\n",
      "Sum without nan ties: 103423\n",
      "Sum without nan defeats: 136475\n",
      "Sum without nan goals: 49366\n",
      "Sum without nan yellowCards: 56274\n",
      "Sum without nan yellowReds: 1662\n",
      "Sum without nan redCards: 1834\n",
      "Sum without nan rater1: 32931.75\n",
      "Sum without nan rater2: 37743.0\n",
      "Sum without nan meanIAT: 50509.50080909433\n",
      "Sum without nan meanExp: 65934.70588842861\n"
     ]
    }
   ],
   "source": [
    "#np.nansum\n",
    "for col_index in range(len(quantitative)):\n",
    "    print(\"Sum without nan {}: {}\".format(quantitative.labels[col_index],np.nansum(quantitative.column(col_index))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More interesting than inspecting non-nan sum, is actually looking at overall means. However, like we explained above, you might run into some issues if your data contains missing values. For this we will use **np.nanmean**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean height: 181.93593798236887\n",
      "Mean weight: 76.07566157805056\n",
      "Mean games: 2.921165803818446\n",
      "Mean victories: 1.278343879256033\n",
      "Mean ties: 0.7082408853096667\n",
      "Mean defeats: 0.934581039252746\n",
      "Mean goals: 0.33805845454296435\n",
      "Mean yellowCards: 0.3853644506532994\n",
      "Mean yellowReds: 0.011381378913633002\n",
      "Mean redCards: 0.012559235215164215\n",
      "Mean rater1: 0.2642552218325964\n",
      "Mean rater2: 0.3028622784281943\n",
      "Mean meanIAT: 0.3462756714022852\n",
      "Mean meanExp: 0.4520255434026573\n"
     ]
    }
   ],
   "source": [
    "for col_index in range(len(quantitative)):\n",
    "    print(\"Mean {}: {}\".format(quantitative.labels[col_index],np.nanmean(quantitative.column(col_index))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will repeat procedure as we did above to find the median- that is, ignoring the nan values. We will use the function **np.nanmedian**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median height: 182.0\n",
      "Median weight: 76.0\n",
      "Median games: 2.0\n",
      "Median victories: 1.0\n",
      "Median ties: 0.0\n",
      "Median defeats: 1.0\n",
      "Median goals: 0.0\n",
      "Median yellowCards: 0.0\n",
      "Median yellowReds: 0.0\n",
      "Median redCards: 0.0\n",
      "Median rater1: 0.25\n",
      "Median rater2: 0.25\n",
      "Median meanIAT: 0.336628162642721\n",
      "Median meanExp: 0.356445562281524\n"
     ]
    }
   ],
   "source": [
    "for col_index in range(len(quantitative)):\n",
    "    print(\"Median {}: {}\".format(quantitative.labels[col_index],np.nanmedian(quantitative.column(col_index))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 1 <a id='section4'></a>\n",
    "---\n",
    "We suspect that an interesting variable to observe has to do with the skin tones of the player. On our dataset we have two variables that contain that information-namely `rater1` and `rater2`. Since deciding under what catagorie (from very light skin- very dark skin) each player fits according to rating is very subjective depending on the eye of the onbserver, we will look into each of these variables individually and then we will take the average of the two variables and use that as a new metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the average of the two rates requires a series of steps. We will: \n",
    "1. Create get the average of the two raters and assign it to a new variable called `avg_rate`\n",
    "2. Add it to the orignal data table: `soccer`\n",
    "3. Remove from the data table any column that has missing data (nan) for the `avg_rate` column, and assign this clean table to `cleaned_soccer.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rate = (soccer.column('rater1') + soccer.column('rater2'))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add it to the data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "soccer.append_column('avgRate', avg_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns.\n",
    "\n",
    "Hint: We will use the method exclude in the Tables library to \"exclude\" certain rows form for data. We will first create an array called to_exclude with the index of the rows we want to remove and then we will add feed it to the exclude method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude= make_array()\n",
    "for row_index in range(len(soccer.column(\"avgRate\"))):\n",
    "    if np.isnan(soccer.column(\"avgRate\").item(row_index)):\n",
    "        to_exclude= np.append(to_exclude,int(row_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_excluded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-adbe2cc9a844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaned_soccer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoccer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_excluded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcleaned_soccer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_excluded' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_soccer = soccer.exclude(to_excluded)\n",
    "cleaned_soccer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify that we obtained the desired output. We will  compare the size length of the original data table (soccer) to the new one (cleaned_soccers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nan {}: {}\".format(cleaned_soccer.labels[28],sum(np.isnan(cleaned_soccer.column(28)))))\n",
    "print(\"\")\n",
    "print(\"The orginal data table, soccer, has {} rows, while the new one, cleaned_soccer, has {} rows. \".format(len(soccer.column(1)), len(cleaned_soccer.column(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to inspect the number of red, yellow, and yellow-red cards by skin color according to the two raters, and the average rate. To do this, we will\n",
    "\n",
    "Create subtables using group, sort, and select.\n",
    "Plot the results of each rater group by the number of red cards awarded to players based on their skin color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rater 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table\n",
    "#group \n",
    "rater1_cards = cleaned_soccer.group('rater1',np.mean)\n",
    "#sort\n",
    "rater1_cards.sort('redCards mean', descending=True)\n",
    "#select\n",
    "rater1_cards.select(['rater1','redCards mean', 'yellowCards mean', 'yellowReds mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "rater1_cards.select(\"redCards mean\",\"rater1\").plot(\"rater1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rater 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table\n",
    "#group \n",
    "rater2_cards = cleaned_soccer.group('rater2',np.mean)\n",
    "#sort\n",
    "rater2_cards.sort('redCards mean', descending=True)\n",
    "#select\n",
    "rater2_cards.select(['rater2','redCards mean', 'yellowCards mean', 'yellowReds mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "rater2_cards.select(\"redCards mean\", \"rater2\").plot(\"rater2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table\n",
    "#group \n",
    "avgRate_cards = cleaned_soccer.group('avgRate',np.mean)\n",
    "#sort\n",
    "avgRate_cards.sort('redCards mean', descending=True)\n",
    "#select\n",
    "avgRate_cards.select(['avgRate','redCards mean', 'yellowCards mean', 'yellowReds mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "avgRate_cards.select(\"redCards mean\",\"avgRate\").plot(\"avgRate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 2:<a id='section5'></a>\n",
    "--- \n",
    "\n",
    "From the previous notebook, we observed how grouping by position reveals interesting information about what players get a red card. Maybe the number of red cards is depending on the position, and not on the skin tone. Maybe many of the positions that get red carded are played by darker skin players, and that is why this we hypothesize that the skin tone is related to red cards. We will explore these questions further by looking into the position of the players. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since our end goal is to create a model with this table, we have to think about what type of data does the model takes. For the most part, the models you have covered in class only take numerical values. You might be wondering, how can we numerically encode categorical data such as position. One option is to use a technique called `one-hot encododing` You can learn more about it here #[one-hot](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there does not exist an easy way to do this using the Tables library, we will create it ourselves. It should have: \n",
    "\n",
    "1. A new column for each of the positions\n",
    "2. Each new column should have the same number of rows as the data set, but made up of zeros on every entry except the ones where the value on the position column matches the column name. For example\n",
    "  \n",
    "|Postion| Attacking Midfielder| Center Back|\n",
    "|-------|---------------------|-----------|\n",
    "| Attacking Midfielder| 1|0|\n",
    "|Center Back| 0 |1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT WORRY ABOUT THE IMPLEMENTATION BELOW.\n",
    "# On this cell we have made a new dictionary where the keys are the positions\n",
    "# and the values are columns made up of the 0's and 1' following the structure above. \n",
    "\n",
    "position_label=['Attacking Midfielder','Center Back','Center Forward','Center Midfielder','Defensive Midfielder','Goalkeeper','Left Fullback', 'Left Midfielder', 'Left Winger', 'Right Fullback', 'Right Midfielder', 'Right Winger']\n",
    "cat_levels = {label:list() for label in position_label}\n",
    "for entry in cleaned_soccer.column(\"position\"):\n",
    "    for key, value in cat_levels.items():\n",
    "        if entry == key:\n",
    "            cat_levels[entry].append(1)\n",
    "        else:\n",
    "            cat_levels[key].append(0)\n",
    "\n",
    "# Saving the 12 key value pairs on the dictioanry to a list that will serve as the new columns for the data frame\n",
    "dataSource = []\n",
    "for key, value in cat_levels.items():\n",
    "    dataSource.append(key)\n",
    "    dataSource.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soccer_one_hot= cleaned_soccer.with_columns(*dataSource).drop(\"position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soccer_one_hot.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 3:<a id='section6'></a>\n",
    "---\n",
    "Another feature that might be interesting to observe is the number of cards per game. On the section below we will create two new features **yellowCardsPerGame**  and **redCardsPerGame**, and then add it to our newly created data table **soccer_one_hot**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yellow Cards\n",
    "soccer_one_hot=soccer_one_hot.with_columns(\"yellowCardsPerGame\",soccer_one_hot.column('yellowCards') / soccer_one_hot.column('games'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Cards\n",
    "soccer_one_hot=soccer_one_hot.with_column(\"redCardsPerGame\",soccer_one_hot.column('redCards') / soccer_one_hot.column('games'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soccer_one_hot.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 4:<a id='section7'></a>\n",
    "---\n",
    "From the 3 rows above we can notice something interesting in the total number of cards per game that might reveal insights about which players get carded how often and which type of card. On the cells below, we will group by the player to get the average number of red and yellow cards that players get per game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soccer_one_hot.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_players= soccer_one_hot.group('player',np.mean)\n",
    "grouped_players.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some interesting observations that come from grouping this way. This first is that, there are some players that play on multiple positions, and the second is that there are is definitely some players that get carded more often than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 5:<a id='section8'></a>\n",
    "\n",
    "There are different types of models that we can use to test whether some players receive a card more often than others. On this section, we will build a basic linear regression model using the data table we created above to predict the average number of yellow cards a given player receives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the table again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_players.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will predict the number of yellow cards per game from the mean IAT score. To do this, we will begin by selecting these two columns and producing a scatter plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_players.select(\"meanIAT mean\", 'yellowCardsPerGame mean').scatter(\"meanIAT mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that overplotting makes it difficult to interpret the plot. But, let's look at the correlation between the two variables. \n",
    "\n",
    "In order to do that, we must convert our values to standard units. We will use the function defined below-called standard_units to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(any_numbers):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    return (any_numbers - np.nanmean(any_numbers))/np.nanstd(any_numbers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply this function to average yellow card per game, and to the meanExp and assign them to new variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanExp_standard = standard_units(grouped_players.column(\"meanIAT mean\"))\n",
    "yellow_standard = standard_units(grouped_players.column('yellowCards mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a new data table containing\n",
    "\n",
    "1. the standardized variables found above\n",
    "    * meanExp_standard\n",
    "    * yellow_standard\n",
    "2. the original values\n",
    "   * meanIAT mean\n",
    "    * yellowCardsPerGame mean\n",
    "3. player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_std =  Table().with_columns([\"meanIAT mean\",grouped_players.column(\"meanIAT mean\"),\n",
    "                                    'yellowCardsPerGame mean',grouped_players.column('yellowCardsPerGame mean'),\n",
    "                                    'meanIAT mean_standard',meanExp_standard,\n",
    "                                    'yellow_standard',  yellow_standard,\n",
    "                                    \"player\", grouped_players.column(\"player\")])\n",
    "yellow_std.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the standardized values we just found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_std.select('meanIAT mean_standard', 'yellow_standard').scatter('meanIAT mean_standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the points look about the same as they did before, but now the diagram is drawn on the same scale, making it easier to identify linear relations. \n",
    "\n",
    "Using standard units also let's compute the correlation coefficient, *r*. The following is drawn from the [Data 8 Textbook section 15.1](https://www.inferentialthinking.com/chapters/15/1/Correlation.html)\n",
    "\n",
    "**The Formula for $r$**:\n",
    "\n",
    "**$r$ is the average of the products of the two variables when both variables are measured in standard units.**\n",
    "\n",
    "Let's define a function ``correlation`` that takes a table and the labels of two columns in the table. The function returns $r$, the mean of the products of those column values in standard units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(t, x, y):\n",
    "    \"\"\"\n",
    "    t: Data table \n",
    "    x: column label for x coordinate\n",
    "    y: column label for y coordinate \n",
    "    \"\"\"\n",
    "    return np.nanmean(standard_units(t.column(x))*standard_units(t.column(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find the correlation for `meanIAT mean_standard` and `yellow_standard`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(yellow_std, 'meanIAT mean_standard','yellow_standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a very small positive correlation between meanIAT and the number of yellow cards. \"The correlation coefficient measures the strength of the linear relationship between two variables. Graphically, it measures how clustered the scatter diagram is around a straight line.\" [source](https://www.inferentialthinking.com/chapters/15/1/Correlation)\n",
    "\n",
    "Now we can use this information to create a simple model. As a reminder, our basic model has the form of \n",
    "\n",
    "**estimated value = slope $*$ feature column $+$ y-intercept**\n",
    " \n",
    "To compute this, we need to introduce two new functions. Namely, we need a function to compute the ``slope`` and the ``y-intercept``(Make sure to click on the link above if you want to learn why we are using these functions).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(t, label_x, label_y):\n",
    "    r = correlation(t, label_x, label_y)\n",
    "    return r*np.nanstd(t.column(label_y))/np.nanstd(t.column(label_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercept(t, label_x, label_y):\n",
    "    return np.nanmean(t.column(label_y)) - slope(t, label_x, label_y)*np.nanmean(t.column(label_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, will use them to build our model.\n",
    "\n",
    "Calculate\n",
    "1. Correlation\n",
    "2. Slope\n",
    "3. Y-Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_std_r = correlation(yellow_std, \"meanIAT mean_standard\", 'yellow_standard')\n",
    "yellow_std_slope = slope(yellow_std, 'meanIAT mean_standard', 'yellow_standard')\n",
    "yellow_std_intercept = intercept(yellow_std, 'meanIAT mean_standard', 'yellow_standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the regression function using the values found above and assign its calculated values to a new column called `Regression_Prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_std = yellow_std.with_column(\n",
    "    'Regression_Prediction', yellow_std_slope*yellow_std.column('meanIAT mean_standard') + yellow_std_intercept\n",
    ")\n",
    "yellow_std.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot you original data and the regression prediction line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yellow_std.select(\"meanIAT mean_standard\", \"yellow_standard\", \"Regression_Prediction\").scatter(\"meanIAT mean_standard\")\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done! In here we constructed a very basic linear regression model using only one feature/column to predict the average number of yellow cards given per game.\n",
    "\n",
    "Now it is your turn to create your own model using metrics and features of your choice. As you might have noticed there are some outcomes from the decision points that we did not include in our analysis, for instance, the player's position. This will require a multi-linear regression since now we have a feature for each position. When you build your models, you will sometimes find this to be the case, and you will need to change your model and its components along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Deciding your own adventure! <a id='section9'></a>\n",
    "---\n",
    "\n",
    "On this section of the notebook, you will also have to face the difficult decision that data scientists face when they build their models. Decisions such as:\n",
    "* picking a dataset\n",
    "* picking certain variables while discarding others\n",
    "* creating new metrics\n",
    "* handling outliers \n",
    "* choosing one model over another \n",
    "will have an incredible impact over the final results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following make sure to \n",
    "1. Choose one of the options provided \n",
    "2. Support your decision by including visualizations \n",
    "3. Provide a short explanation to why you think that variable or metric matters for determining if certain players get penalized more than others\n",
    "\n",
    "Note: At the end of this exercise your final outcome should be different(for the most part) to that of your peers.  \n",
    "\n",
    "You can look at the EDA notebook you completed last week to get inspired! \n",
    "\n",
    "For this exercise make sure to use the table: **cleaned_soccer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 1:<a id='section10'></a>\n",
    "\n",
    "#### a) Select estimation (variable): Predict on yellow cards\n",
    "#### b) Select estimation (variable): Predict on red cards\n",
    "\n",
    "*On our model we chose `yellow cards`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_choice= r\"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_response=r\"  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 2:<a id='section11'></a>\n",
    "\n",
    "\n",
    "#### a) Select estimation (metric): yellow/red cards (per game)\n",
    "#### b) Select estimation (metric):  yellow/red cards (total)\n",
    "#### c) Select estimation (variable): yellow/red cards (percent of total)\n",
    "*On our model we chose `yellow cards per game`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_choice= r\"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_response=r\"  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 3:<a id='section12'></a>\n",
    "\n",
    "#### a) Select estimation (metric) : Mean of yellow/red cards\n",
    "#### b) Select estimation (metric): Count/sum of yellow/red cards\n",
    "#### c) Select estimation (metric): Median of yellow/red cards\n",
    "\n",
    "*On our model we chose `yellow cards per game mean`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_choice= r\"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_response=r\"  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 4:<a id='section13'></a>\n",
    "\n",
    "#### a)  Select predictor (feature): avg goals/game\n",
    "#### b)  Select predictor (feature): average winning/losing rate\n",
    "\n",
    "*On our model we chose `meanIAT mean`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_choice= r\"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_response=r\"  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 5:<a id='section14'></a>\n",
    "\n",
    "#### a)  Select predictor (feature): BMI\n",
    "#### b)  Select predictor (feature)  average winning/losing rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_choice= r\"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5_response=r\"  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 6:<a id='section15'></a>\n",
    "\n",
    "\n",
    "#### a)  Select predictor (feature): weight \n",
    "#### b)  Select predictor (feature): age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_choice= r\"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6_response=r\"  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Point 7:<a id='section16'></a>\n",
    "\n",
    "#### a)  Select model: Simple linear regression (using one feature from the ones you created above)\n",
    "\n",
    "*On our model we chose `meanIAT mean`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_choice= r\"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7_response=r\"  \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Keilyn Yuzuki, Lisa Zhou, Karla Palos\n",
    "\n",
    "Data Science Modules: https://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
